{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bf15761-0a4c-4374-912c-6d1b1cb61d5e",
   "metadata": {},
   "source": [
    "# Assignment 4\n",
    "*Author: Logan Reine*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8907a8f0-7249-41ec-bdca-cf52f4234abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run MLequations_v2.ipynb\n",
    "\n",
    "ff = lambda x, y, z = \"bits\" : print(\"{} {:.4f} {}\".format(x, y, z))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d20d9826-ee8f-4329-afab-00c3205c25d0",
   "metadata": {},
   "source": [
    "# 1 Calculating Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d066d77-5200-4a42-a1fe-19505283161e",
   "metadata": {},
   "source": [
    "The figure below shows a set of eight Scrabble pieces.\n",
    "\n",
    "![Local Image](scrabble.png)\n",
    "\n",
    "**1. What is the entropy (in bits) of the letters in this set?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d39feb51-0e87-4b0e-87de-55913e234ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 2.4056 bits\n"
     ]
    }
   ],
   "source": [
    "scrabble = pd.DataFrame({\n",
    "    'Letters':['O', 'X', 'Y', 'M', 'O', 'R', 'O', 'N']\n",
    "})\n",
    "ff(\"Entropy:\", H(scrabble))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c32937-3e2b-496b-979a-d899e06ba572",
   "metadata": {},
   "source": [
    "**2. What would be the reduction in entropy (i.e., the information gain) in bits if we split these letters into two sets, one containing the vowels and the other containing the consonants?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de3e979d-b548-46a2-a4aa-3b7e5146ecca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Information Gain: 0.9544 bits\n"
     ]
    }
   ],
   "source": [
    "vows = pd.DataFrame({\n",
    "    'Vowels':['O', 'O', 'O']\n",
    "})\n",
    "cons = pd.DataFrame({\n",
    "    'Consonants':['X', 'M', 'R', 'N', 'Y']\n",
    "})\n",
    "\n",
    "r_vow = 3/8 * H(vows)\n",
    "r_con = 5/8 * H(cons)\n",
    "t_rem = r_vow + r_con\n",
    "\n",
    "ff(\"\\nInformation Gain:\", H(scrabble) - t_rem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d995a6-2e57-4063-9eff-9f1d1aca33e6",
   "metadata": {},
   "source": [
    "**3. What is the maximum possible entropy (in bits) for a set of eight Scrabble pieces?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8c3b990-edb6-44f0-905c-465f578150cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Possible Entropy: 3.0000 bits\n"
     ]
    }
   ],
   "source": [
    "ran_scrabble_8 = pd.DataFrame({\n",
    "    'Letters':['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n",
    "})\n",
    "ff(\"Max Possible Entropy:\", H(ran_scrabble_8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a016785-1c34-4913-ae58-bb5b8421c2e0",
   "metadata": {},
   "source": [
    "**4. In general, which is preferable when you are playing Scrabble: a set of letters with high entropy, or a set of letters with low entropy?**\n",
    "\n",
    "    A higher entropy is preferable. The higher the variability in Scrabble tiles, the wider the range in possible word choices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3181b5f6-ab1b-4182-a764-392ea220c52c",
   "metadata": {},
   "source": [
    "# 2 Decision Tree Construction\n",
    "\n",
    "**1. Using this dataset, construct the decision tree that would be generated by the ID3 algorithm, using entropy-based information gain.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6706349e-5899-4760-9428-37d8b89ae95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good Behavior 0.0817 bits\n",
      "Age Below 30 0.4591 bits\n",
      "Drug Dependent 0.1909 bits\n"
     ]
    }
   ],
   "source": [
    "# ID \tGood Behavior \tAge Below 30     Drug Dependent \t Recidivist\n",
    "rec = pd.read_csv(\"recidivistADT.tsv\", delimiter = '\\t')\n",
    "\n",
    "for x in rec.columns[1:-1]:\n",
    "    ff(x, IG(rec[x], rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce9b4d01-9e6d-4ef2-8a88-c744c88dd2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  Good Behavior  Drug Dependent  Recidivist\n",
      "1   2          False           False       False\n",
      "3   4           True           False       False\n",
      "4   5           True            True        True\n",
      "5   6           True           False       False\n",
      "Good Behavior 0.1226 bits\n",
      "Drug Dependent 0.8113 bits\n"
     ]
    }
   ],
   "source": [
    "t_30 = rec[rec['Age Below 30'] == True]\n",
    "t_30 = t_30.drop(columns = ['Age Below 30'])\n",
    "\n",
    "f_30 = rec[rec['Age Below 30'] == False]\n",
    "f_30 = f_30.drop(columns = ['Age Below 30'])\n",
    "\n",
    "print(f_30)\n",
    "for x in f_30.columns[1:-1]:\n",
    "    ff(x, IG(f_30[x], f_30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "426b6e94-01e7-4aca-a564-5e435c3764a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good Behavior 0.0000 bits\n"
     ]
    }
   ],
   "source": [
    "t_drug = f_30[f_30['Drug Dependent'] == True]\n",
    "t_drug = t_drug.drop(columns = ['Drug Dependent'])\n",
    "\n",
    "f_drug = f_30[f_30['Drug Dependent'] == False]\n",
    "f_drug = f_drug.drop(columns = ['Drug Dependent'])\n",
    "\n",
    "for x in f_drug.columns[1:-1]:\n",
    "    ff(x, IG(f_drug[x], f_drug))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98e6ac1a-d1a5-4421-9a0f-33c558add696",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         [Age < 30]                         \n",
      "                       TRUE     FALSE                       \n",
      "                       /           \\                        \n",
      "                      /             \\                       \n",
      "                               [Drug Dependent]\n",
      "                                TRUE     FALSE\n",
      "                                /            \\\n",
      "                               /              \\\n",
      "                                         [Good Behavior]\n",
      "                                          TRUE     FALSE\n",
      "                                          /            \\\n",
      "                                         /              \\\n"
     ]
    }
   ],
   "source": [
    "print('{:^{width}}'.format('[Age < 30]', width = 60))\n",
    "print('{:^{width}}'.format('TRUE     FALSE', width = 60))\n",
    "print('{:^{width}}'.format('/           \\\\', width = 60))\n",
    "print('{:^{width}}'.format('/             \\\\', width = 60))\n",
    "print('{:>{width}}'.format('[Drug Dependent]', width = 47))\n",
    "print('{:>{width}}'.format('TRUE     FALSE', width = 46))\n",
    "print('{:>{width}}'.format('/            \\\\', width = 46))\n",
    "print('{:>{width}}'.format('/              \\\\', width = 47))\n",
    "print('{:>{width}}'.format('[Good Behavior]', width = 56))\n",
    "print('{:>{width}}'.format('TRUE     FALSE', width = 56))\n",
    "print('{:>{width}}'.format('/            \\\\', width = 56))\n",
    "print('{:>{width}}'.format('/              \\\\', width = 57))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6df78b0-036a-41cd-bbca-b4b26b3a100e",
   "metadata": {},
   "source": [
    "**2. What prediction will the decision tree generated in part (a) of this question return for the following query?**\n",
    "\n",
    "**Good Behavior** = false, **Age Below 30** = false, **Drug Dependent** = true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c874dad4-9da9-48d5-8a9d-8c5456f36296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  Good Behavior  Drug Dependent  Recidivist\n",
      "1   2          False           False       False\n",
      "3   4           True           False       False\n",
      "4   5           True            True        True\n",
      "5   6           True           False       False\n",
      "\n",
      "    ID  Good Behavior  Recidivist\n",
      "4   5           True        True\n"
     ]
    }
   ],
   "source": [
    "# Older than 30\n",
    "print(f_30)\n",
    "\n",
    "# are Drug Dependent\n",
    "print('\\n',t_drug)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661672cd-fc7b-4999-9626-5560a941d7e7",
   "metadata": {},
   "source": [
    "    recidivist = true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb18eea-9463-41cc-acb0-c42fc094b5d6",
   "metadata": {},
   "source": [
    "**3. What prediction will the decision tree generated in part (a) of this question return for the following query?**\n",
    "\n",
    "**Good Behavior** = true, **Age Below 30** = true, **Drug Dependent** = false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "727a8913-7559-4e62-95a4-aa9254bc2411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  Good Behavior  Drug Dependent  Recidivist\n",
      "0   1          False           False        True\n",
      "2   3          False           False        True\n"
     ]
    }
   ],
   "source": [
    "# Younger than 30\n",
    "print(t_30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d51d10a-45e1-4d11-8066-923eb0562fcc",
   "metadata": {},
   "source": [
    "    recidivist = true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917e2688-53b4-41f5-9ff4-493edb2066e7",
   "metadata": {},
   "source": [
    "# 3 Information Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750bcfbb-8133-4301-9676-4de919390857",
   "metadata": {},
   "source": [
    "**1. Calculate the entropy for this dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58af6522-ad77-48ea-9493-c69e0b1d7d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Census Entropy: 1.2988 bits\n"
     ]
    }
   ],
   "source": [
    "census = pd.read_csv(\"sample_census.tsv\", delimiter = '\\t')\n",
    "ff('Census Entropy:', H(census))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356949f4-3c98-4cfc-9fab-fe16edd197a1",
   "metadata": {},
   "source": [
    "**2. Calculate the Gini index for this dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbed5f49-1517-44f7-8c4c-5706355fce3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini Index: 0.5312 bits\n"
     ]
    }
   ],
   "source": [
    "ff('Gini Index:', gini(census))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bd901e-397d-424e-ae75-7e00c2e64c71",
   "metadata": {},
   "source": [
    "**3. When building a decision tree, the easiest way to handle a continuous feature is to define a threshold around which splits will be made. What would be the optimal threshold to split the continuous Age feature (use information gain based on entropy as the feature selection measure)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f92df1b5-f6e0-4697-a9f4-eff1cf6d2979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  Age Annual Income\n",
      "2   3   18     below 25K\n",
      "5   6   24     below 25K\n",
      "3   4   28       25K-50K\n",
      "4   5   37       25K-50K\n",
      "0   1   39       25K-50K\n",
      "7   8   40      over 50K\n",
      "1   2   50       25K-50K\n",
      "6   7   52       25K-50K\n"
     ]
    }
   ],
   "source": [
    "print(census[['ID', 'Age', 'Annual Income']].sort_values(by = 'Age'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7196db4-f480-4436-a731-3ec86bf25f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info Gain > 27: 0.8113 bits\n",
      "Info Gain > 39: 0.3476 bits\n",
      "Info Gain > 49: 0.2044 bits\n"
     ]
    }
   ],
   "source": [
    "threshold = [27, 39, 49]\n",
    "\n",
    "for x in threshold:\n",
    "    i = 0\n",
    "    thresh_census = census.sort_values(by = 'Age')\n",
    "    for y in thresh_census['Age']:\n",
    "        if thresh_census.at[i, 'Age'] > x:\n",
    "            thresh_census.at[i, 'Age'] = 1\n",
    "        else: \n",
    "            thresh_census.at[i, 'Age'] = 0\n",
    "        i += 1\n",
    "    print('Info Gain > {}: {:.4f} bits'.format(x, IG(thresh_census['Age'], thresh_census)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6631b585-a506-4657-985a-40399555cd56",
   "metadata": {},
   "source": [
    "**4. Calculate information gain (based on entropy) for the Education, Marital Status, and Occupation features.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8ce7475-96a0-41da-adfa-c8307f69bdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education 0.7988 bits\n",
      "Marital Status 0.5488 bits\n",
      "Occupation 0.7044 bits\n"
     ]
    }
   ],
   "source": [
    "for x in census.columns[2:-1]:\n",
    "    ff(x, IG(census[x], census))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10dec01-1b0f-42e5-97b6-cd66aaf52929",
   "metadata": {},
   "source": [
    "**5. Calculate the information gain ratio (based on entropy) for Education, Marital Status, and Occupation features.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72438653-3e78-41af-ae7c-2e21997ffb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education 0.5683 bits\n",
      "Marital Status 0.3904 bits\n",
      "Occupation 0.3697 bits\n"
     ]
    }
   ],
   "source": [
    "for x in census.columns[2:-1]:\n",
    "    ff(x, IG(census[x], census) / H(census[[x]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8356af7-e249-411d-953a-d0a695fdda09",
   "metadata": {},
   "source": [
    "**6. Calculate information gain using the Gini index for the Education, Marital Status, and Occupation features.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf2d37b3-adfa-4ba8-9f0f-607732f06ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education 0.2812 bits\n",
      "Marital Status 0.1771 bits\n",
      "Occupation 0.2396 bits\n"
     ]
    }
   ],
   "source": [
    "for x in census.columns[2:-1]:\n",
    "    ff(x, gini_IG(census[x], census))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f28ea5-c26b-455c-a3d1-0c9a9b0f7eaa",
   "metadata": {},
   "source": [
    "# 4 Decision Tree Error Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef322672-22a9-4ac3-897a-ad79c74f9f52",
   "metadata": {},
   "source": [
    "**Shown in the figure below shows a decision tree for predicting heart disease. The descriptive features in this domain describe whether the patient suffers from chest pain (Chest Pain) and blood pressure (Blood Pressure). The binary target feature is Heart Disease. The table below the diagram lists a pruning set from this domain.**\n",
    "\n",
    "![Local Image](heart.png)\n",
    "\n",
    "**Using the pruning set, apply reduced error pruning to the decision tree. Assume that the algorithm is applied in a bottom-up, left-to-right fashion. For each iteration of the algorithm, indicate the subtrees considered as pruning candidates, explain why the algorithm chooses to prune or leave these subtrees in the tree, and illustrate the tree that results from each iteration.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36add512-d59e-407a-9c5c-73d5488318a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Blood Pressure  Heart Disease\n",
      "0           high          False\n",
      "4           high          False\n",
      "2            low          False\n",
      "\n",
      "    ID  Chest Pain Blood Pressure  Heart Disease\n",
      "0   1       False           high          False\n",
      "2   3       False            low          False\n",
      "4   5       False           high          False\n",
      "1   2        True            low           True\n",
      "3   4        True           high           True\n"
     ]
    }
   ],
   "source": [
    "hdisease = pd.read_csv(\"h_disease.tsv\", delimiter = '\\t')\n",
    "chest_pain_false = hdisease[hdisease['Chest Pain'] == False]\n",
    "print(chest_pain_false[['Blood Pressure', 'Heart Disease']].sort_values(by = 'Blood Pressure'))\n",
    "print(\"\\n\", hdisease.sort_values(by = 'Chest Pain'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cde9df-e93f-4914-a782-ee1d57bff060",
   "metadata": {},
   "source": [
    "    Below is the first subtree to be considered.  The parent node returns false, which is correct for 3/3 cases -- returns false if chest pain is false -- so the error rate is 0.  If blood pressure is low, the right leaf returns false, which is correct in 1/1 cases.  If blood pressure is high, The left leaf returns true. This is correct in 0/2 cases, so the error rate is two. The summed error rate of the children nodes exceeds the error rate of the subtree's root node, so this subtree is pruned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56796f34-815d-4d6b-922c-e69cd48d3bd0",
   "metadata": {},
   "source": [
    "![Local Image](heart_bp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbe3be0-2dd3-4e6b-8ff5-cf4add555d6d",
   "metadata": {},
   "source": [
    "![Local Image](heart_bp2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ded018-2067-430f-b790-aab5879505f8",
   "metadata": {},
   "source": [
    "        Above is the decision tree after the first iteration of pruning.  The root node returns true for the target feature, which misclassifies the target feature in 3/5 cases -- error rate = 3.  After partitioning the data by 'chest pain', the left leaf returns false, this classifies the target feature correctly in 3/3 cases -- error rate = 0.  By default, in a binary decision structure this would mean the sister node also holds an error rate of 0.  The summed error rate of the child nodes is 0, which is less than the root node with an error rate of 3.  This subtree is not pruned, and this would be the final iteration as the entire tree has now been reviewed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf243ff-7601-441d-8c85-ce8a0ca2edb2",
   "metadata": {},
   "source": [
    "# 5 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e506b92-6b26-462d-9c65-18887a328874",
   "metadata": {},
   "outputs": [],
   "source": [
    "hd_risk = pd.read_csv('risk.tsv', delimiter = '\\t')\n",
    "risk_a = pd.read_csv('risk_A.tsv', delimiter = '\\t')\n",
    "risk_b = pd.read_csv('risk_B.tsv', delimiter = '\\t')\n",
    "risk_c = pd.read_csv('risk_C.tsv', delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64220cf-493e-4ee3-b626-4c768887145d",
   "metadata": {},
   "source": [
    "**1. Using these bootstrap samples create the decision trees that will be in the random forest model (use entropy based information gain as the feature selection criterion).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77566d6b-55de-405e-b896-c073d1b68968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- SAMPLE A -\n",
      "    ID Exercise Family  Risk\n",
      "0   1    daily    yes   low\n",
      "1   2   weekly    yes  high\n",
      "2   2   weekly    yes  high\n",
      "3   5   rarely     no  high\n",
      "4   5   rarely     no  high\n",
      "\n",
      "- SAMPLE A INFORMATION GAIN - \n",
      "Exercise 0.7219 bits\n",
      "Family 0.1710 bits\n"
     ]
    }
   ],
   "source": [
    "print('\\t- SAMPLE A -\\n', risk_a)\n",
    "print('\\n- SAMPLE A INFORMATION GAIN - ')\n",
    "for x in risk_a.columns[1:-1]:\n",
    "    ff(x, IG(risk_a[x], risk_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f929625-fa0d-4261-85d6-556f7e990f89",
   "metadata": {},
   "source": [
    "    'Exercise' has the highest information gain, and coincidentally distributes the data into pure subsets. Since the partitioned sets are pure, there isn't a need to develop a decision tree any further.\n",
    "![local image](sample_a.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07db985d-2331-481c-b656-3cc9b83c3337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- SAMPLE B -\n",
      "    ID  Smoker  Obese  Risk\n",
      "0   1   False  False   low\n",
      "1   2    True  False  high\n",
      "2   2    True  False  high\n",
      "3   4    True   True  high\n",
      "4   5    True   True  high\n",
      "\n",
      "- SAMPLE B INFORMATION GAIN - \n",
      "Smoker 0.7219 bits\n",
      "Obese 0.1710 bits\n"
     ]
    }
   ],
   "source": [
    "print('\\t- SAMPLE B -\\n', risk_b)\n",
    "print('\\n- SAMPLE B INFORMATION GAIN - ')\n",
    "for x in risk_b.columns[1:-1]:\n",
    "    ff(x, IG(risk_b[x], risk_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94129f7a-cf91-4026-8f8a-70e39fca3133",
   "metadata": {},
   "source": [
    "    The 'smoker' feature has the highest information gain.  Once more, this discriptive feature splits the remaining data into pure sets, so expanding a decision tree any further isn't necessary.\n",
    "\n",
    "![Local Image](sample_b.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "883b9ea5-e0bf-4d1a-9243-f57fff9113da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- SAMPLE C -\n",
      "    ID  Obese Family  Risk\n",
      "0   1  False    yes   low\n",
      "1   1  False    yes   low\n",
      "2   2  False    yes  high\n",
      "3   4   True    yes  high\n",
      "4   5   True     no  high\n",
      "\n",
      "- SAMPLE C INFORMATION GAIN - \n",
      "Obese 0.4200 bits\n",
      "Family 0.1710 bits\n"
     ]
    }
   ],
   "source": [
    "print('\\t- SAMPLE C -\\n', risk_c)\n",
    "print('\\n- SAMPLE C INFORMATION GAIN - ')\n",
    "for x in risk_c.columns[1:-1]:\n",
    "    ff(x, IG(risk_c[x], risk_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eb13e9-331d-4636-b33d-3d4758fbb821",
   "metadata": {},
   "source": [
    "    'Obese' has the highest information gain.  'True' under the descriptive feature obese splits the data into a pure subset, but 'False' does not.  Normally we would use the next descriptive feature to filter the data further, but moving into another decision node for 'Family' wouldn't provide anymore information. 'Obese' being false also split 'Family' into a pure set.\n",
    "\n",
    "![Local Image](sample_c.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c846994b-d5aa-41af-b8dc-27ecd2960617",
   "metadata": {},
   "source": [
    "**2. Assuming the random forest model you have created uses majority voting, what prediction will it return for the following query:**\n",
    "\n",
    "**Exercise=rarely, Smoker=false, Obese=true, Family=yes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5b841c-3e6a-4cae-ad7f-bb8906d6c7f2",
   "metadata": {},
   "source": [
    "    Sample tree A returns: High\n",
    "    Sample tree B returns: Low\n",
    "    Sample tree C returns: High\n",
    "\n",
    "    The majority vote is High."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
