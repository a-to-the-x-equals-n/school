{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cryptoanalysis Report\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report breaks down the tools and methods used to decode a shift and substitution cipher. By comparing letter frequencies, pattern recognition, and various phases of trial and (mostly) error, the plaintexts were revealed. As well as writing code in Python to manipulate and reorganize the data into useful metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shift Cipher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the substitution cipher, breaking the shift cipher was fairly intuitive. If we examine the formula for decryption:\n",
    "\n",
    "$d_K(y) = (y - K) \\mod 26$\n",
    "\n",
    "**where**\n",
    "\n",
    "$K$ **is the keyspace,** $0 <= k <= 25$\n",
    "\n",
    "$y$ **is the encrypted message**\n",
    "\n",
    "$d_K$ **is the encryption function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can deduce that there is one integer between 1 and 26 that is shifting each character.\n",
    "\n",
    "since\n",
    "\n",
    "$d_K(e_K(x)) = x \\quad \\forall x \\in P$\n",
    "\n",
    "We see there is only 1 integer used to shift all of the characters in the plaintext. I wrote a `for` loop with 26 iterations that applied the shift to each character of the ciphertext in place, and then printed out all 26 possibilities. I then examined each plaintext to see if one of the solutions was coherent or intelligible. To which there was, **\"It is better to create than to learn. Creating is the essence of life\"**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Substitution Cipher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The substitution cipher was quite more challenging, and required several days of continous brainstorming before the code was *cracked*. The first step was converting some of the data provided in the English statistics PDF from Canvas to a format that I could load into my program. Specifically the bigram matrix, and the probabilities of the characters. I followed this paradigm with the characters in the ciphertext, and parsed the number of occurrences in the cipher to elude any useful insights and deductions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Frequency Analysis**\n",
    "\n",
    "Initially, I would compare frequencies and number of occurrences of individual letters between the English statistics and the ciphertext's statistics. At this point it was very much educated guessing. I'd chose individual characters from both English and the cipher made probabilistic sense. Unfortunately, this wasn't returning anything tangibly useful. Since I was splicing in letters without then being able to test and verify if it was the correct character or not, I realized I needed more information, or **a lot** of luck.\n",
    "\n",
    "**Bigrams**\n",
    "\n",
    "Fortunately, I've taken a machine learning course previously, and I am concurrently taking a course in natural language processing (NLP). Recently, we started working with ngrams and co-occurrence matrices to predict text. I realized some common threads between the two. NLP is formed by predictions that are founded on likelihood of occurrence, given $x$ has already occurred; Bayes' theorem.\n",
    "\n",
    "The next step from here was to compile bigrams of the ciphertext. I already had the bigram data for the characters used in the English language from the PDF. This is where the first break came. I discovered in the cipher's bigram matrix that the character \"**W**\" had *zero* co-occurrence with any letter, save one: \"**S**\".\n",
    "\n",
    "With W pairing with S four times yet never with another character, I knew it had to he a very uncommon letter that only appeared often in tandem with another specific letter. This suggested the classic pairing of **QU**. But after further review, it seemed increasingly incorrect. Soon after, I realized that in almost all instances of **WS**, it was preceeded by another **S**. After this discovery, I was confident **SWS** mapped to **EVE**. In turn, this demonstrated the value of trigrams.\n",
    "\n",
    "**Trigrams**\n",
    "\n",
    "I had to refactor and expand the initial bigram functionality to accommodate trigrams, as well as a print function to show the trigrams. The row headings were the cipher's distinct characters, and the column headings were every arrangement of bigrams in the cipher. This generated a numpy array with the dimensions 22 x 150. Leaving it too large for any meaningful interpretations. A \"top $k$\" function spawned from this challenge, where the matrices would be flattened, sorted, and zipped into a python dictionary of length $k$ where the full trigrams mapped to their corresponding raw counts or frequencies. \n",
    "\n",
    "To narrow my purview, I picked three trigrams from the top ten: **KVS**, **VSG**, and **YVS**. I picked them based on them having some common characters so I could cross reference substitutions, use one trigram as a tool to solve another. I was determined to solve for **the** in the ciphertext, since **the** is the most common trigram in the English language.\n",
    "\n",
    "I've maintained the assumption that **S** -> **e** and **W** -> **v**. The three trigrams **KVS**, **VSG**, and **YVS** all have an **S**. After applying the known substitutions in place:\n",
    "\n",
    "**KVS** -> KV**e**\n",
    "\n",
    "**VSG** -> V**e**G\n",
    "\n",
    "**YVS** -> YV**e**\n",
    "\n",
    "Honing in on **VS** in the ciphertext, it's probabilistically logical that **V** -> **h**, yielding the bigram **he** in the ciphertext.  With in place substitions our trigams are now:\n",
    "\n",
    "**KVS** -> K**he** \n",
    "\n",
    "**VSG** -> **he**G \n",
    "\n",
    "**YVS** -> Y**he** \n",
    "\n",
    "Upon further reviewing of **Khe** and **Yhe**, it's feasible that one of them maps to **she**, the other to **the**. The uncertainty was resolved when I noticed a peculiar sequence in the cipher: **YYSYY**. With current assumptions in place:\n",
    "\n",
    "**YYSYY** -> YY**e**YY\n",
    "\n",
    "if **Y** -> **t** then **YYSYY** -> **ttett**\n",
    "\n",
    "if **Y** -> **s** then **YYSYY** -> **ssess**\n",
    "\n",
    "I stewed on **ttett** to try and imagine plausible scenarios of its usage. With my limited capacity, I couldn't surmise a colloquial context the arrangement **ttett**. But **ssess** *did* resemble accepted sequences. Also, the particular arrangement **ssess** is rare, only appearing in words like **obsess**, **possess**, and **assess**. This unveiling solved the **she** and **the** guesswork as well; **Y** maps to **s**, therefore **YVS** maps to **she**. With current assumptions in place:\n",
    "\n",
    "**KVS** -> K**he**\n",
    "\n",
    "**VSG** -> **he**G\n",
    "\n",
    "**YVS** -> **she**\n",
    "\n",
    "Since **YVS** -> **she**, it is now logically clear that **Y** likely maps to **s**.  With current assumptions in place:\n",
    "\n",
    "**KVS** -> **the**\n",
    "\n",
    "**VSG** -> **he**G\n",
    "\n",
    "**YVS** -> **she**\n",
    "\n",
    "**YYSYY** -> **ssess**\n",
    "\n",
    "At this point, major strides have been achieved. The logical next steps begin to appear as more letters are uncovered. For example, with **ssess** we can logically deduce that the letter before and after the **ss** sequences is going to be a vowel. Broadening the ciphertext containing **YYSYY**, we see **BYYSYYBGB**. With assumptions in place:\n",
    "\n",
    "**BYYSYYBGB** -> B**ssess**BGB\n",
    "\n",
    "I tested **B** mapping to **o**.\n",
    "\n",
    "**BYYSYYBGB** -> **ossesso**G**o**\n",
    "\n",
    "Now the word \"possessor\" seems to appear. After cross validating **G** mapping to **r** with the trigram **heG** (becoming **her**), I'm able to solve for another high frequency character in the ciphertext. My plaintext is now:\n",
    "\n",
    "-O-O---SH-ETO---E-O-R-E------E---O---E-SE-THE-TO--HERTHE-OR--H-\n",
    "\n",
    "-H-E-O--E-TO-O-------E----S--HERS-R-R-SESHETO---ETH-T-T--S---OS\n",
    "\n",
    "S---E-ORSHE-E--EVE-HERSE--THEO----OSSESSORO-TH-T-OR--H--HSHE-E-\n",
    "\n",
    "T--HER-E-OR-----H--HSHEH---EVER-R-TTE--O----O---H-VETO--HERTHET\n",
    "\n",
    "R-TH--TO-----R--E-TSTR----ETOTE--HERTH-T--E--EH--REVE--E--TTO-E\n",
    "\n",
    "Finally, I aim to solve for the last crucial vowel **a**. I scan the plaintext for sequences of **TH-T**, and test subbing in **a**.  Then **p** to complete **possessor**.  So on and so forth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By analyzing character frequencies, letter patterns, and iteratively refining character replacements, I was able to systematically break both ciphers. The methods employed allowed me to identify high probability character mappings while being able to validate them through common ngram sequences. The reliance on statistically likely substitutions minimized errors, and also premiered the effectiveness of analyzing character frequencies and pattern recognition in cryptographic analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
